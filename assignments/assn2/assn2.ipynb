{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate Machine Learning: Assignment 2\n",
    "\n",
    "**Deadline**\n",
    "\n",
    "Assignment 2 is due Wednesday, March 9 11:59pm. Late work will not be accepted as per the course policies (see the Syllabus and Course policies on Canvas).\n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged.\n",
    "\n",
    "You should start early so that you have time to get help if you're stuck. The drop-in office hours schedule can be found on Canvas. You can also post questions or start discussions on Ed Discussion. The assignment may look long at first glance, but the problems are broken up into steps that should help you to make steady progress.\n",
    "\n",
    "**Submission**\n",
    "\n",
    "Submit your assignment as a pdf file on Gradescope, and as a notebook (.ipynb) on Canvas. You can access Gradescope through Canvas on the left-side of the class home page. The problems in each homework assignment are numbered. Note: When submitting on Gradescope, please select the correct pages of your pdf that correspond to each problem. This will allow graders to more easily find your complete solution to each problem.\n",
    "\n",
    "To produce the .pdf, please do the following in order to preserve the cell structure of the notebook:\n",
    "\n",
    "Go to \"File\" at the top-left of your Jupyter Notebook\n",
    "Under \"Download as\", select \"HTML (.html)\"\n",
    "After the .html has downloaded, open it and then select \"File\" and \"Print\" (note you will not actually be printing)\n",
    "From the print window, select the option to save as a .pdf\n",
    "\n",
    "**Topics**\n",
    "\n",
    " * Convolutional neural networks\n",
    " * Gaussian processes\n",
    " * Dirichlet processes\n",
    "\n",
    "This assignment will also help to solidify your Python and Jupyter notebook skills.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Filter through (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we will [\"open the black box\"](https://news.yale.edu/2018/12/10/why-take-ydata-because-data-science-shouldnt-be-black-box) and inspect the filters and feature maps learned by a convolutional neural network trained to classify handwritten digits, using the MNIST database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Visualizing the filters\n",
    "\n",
    "To begin, we load the dataset with 60000 training images and 10000 test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train_binary = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_binary = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize our convolutional neural network similar to the network we used for Assignment 1 Problem 4 except that we now have a few more layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\", name='conv1'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\", name='conv2'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 1\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train_binary, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test_binary, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained and tested the model, let's look at the filters learned in the first convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_conv1 = model.get_layer(name='conv1').get_weights()[0]\n",
    "\n",
    "fig, axs = plt.subplots(4, 8)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(8):\n",
    "        f = filters_conv1[:, :, 0, 8*i+j]\n",
    "        axs[i, j].imshow(f[:, :], cmap='gray')\n",
    "        axs[i, j].axis('off')\n",
    "        axs[i, j].set_title(8*i+j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe what you see. Do (some of) the learned filters make sense to you?\n",
    "\n",
    "Hint: Many filters have been designed and widely applied in image processing. [Here](http://www.theobjects.com/dragonfly/dfhelp/3-5/Content/05_Image%20Processing/Edge%20Detection%20Filters.htm) are some examples of edge detection filters and their effect on the image. You can find the details about each filter by clicking the links at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Markdown Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Visualizing the feature maps\n",
    "\n",
    "We can also look at the corresponding feature map for each filter. There are 32 kernels at the first convolutional layer, so there are 32 feature maps for each sample. feature_map_conv1 is a 4D matrix where the first dimension is the index of the sample and the last dimension is the index of the correpsonding filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_layer_model = keras.Model(inputs=model.input, outputs=model.get_layer('conv1').output)\n",
    "feature_map_conv1 = conv1_layer_model(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly draw 16 samples for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = random.sample(range(1, len(x_test)), 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose two filters among all 32 filters from 3.1, visualize their feature maps. There is no need to modify the code, just run the four cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_n1 = #\n",
    "filter_n2 = #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(filters_conv1[:, :, 0, filter_n1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 8)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "ix=0\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axs[i, 2*j].imshow(x_test[sample_index[4*i+j], :, :, 0], cmap='gray')\n",
    "        axs[i, 2*j].axis('off')\n",
    "        axs[i, 2*j+1].imshow(feature_map_conv1[sample_index[4*i+j], :, :, filter_n1], cmap='gray')\n",
    "        axs[i, 2*j+1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(filters_conv1[:, :, 0, filter_n2], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 8)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "ix=0\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axs[i, 2*j].imshow(x_test[sample_index[4*i+j], :, :, 0], cmap='gray')\n",
    "        axs[i, 2*j].axis('off')\n",
    "        axs[i, 2*j+1].imshow(feature_map_conv1[sample_index[4*i+j], :, :, filter_n2], cmap='gray')\n",
    "        axs[i, 2*j+1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on what you see in the feature maps.\n",
    "* How do they correspond to the original images?\n",
    "* How do they correspond to the filters?\n",
    "* Why might the feature maps be helpful for classifying digits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your markdown here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Fitting a logistic regression model on feature maps\n",
    "\n",
    "The features of the images are further summarized after the second convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2_layer_model = keras.Model(inputs=model.input, outputs=model.get_layer('conv2').output)\n",
    "feature_map_conv2 = conv2_layer_model(x_test)\n",
    "\n",
    "fig, axs = plt.subplots(4, 8)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "ix=0\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axs[i, 2*j].imshow(x_test[sample_index[4*i+j], :, :, 0], cmap='gray')\n",
    "        axs[i, 2*j].axis('off')\n",
    "        axs[i, 2*j+1].imshow(feature_map_conv2[sample_index[4*i+j], :, :, 0], cmap='gray')\n",
    "        axs[i, 2*j+1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and test a logistic regression model to classify two digits of your choice using the features maps at the second convolutional layer as the input. You may use logistic regression functions such as [LogisticRegression in sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Use 80% of the data for training and 20% for test.\n",
    "\n",
    "* How many features are there in your input X? Show the derivation of this number based on the architecture of the convolutional neural network.\n",
    "\n",
    "* How is your logistic regression model related to the fully connected layer and softmax layer in the convolutional neural network?\n",
    "\n",
    "* What is the accuracy of your model? Is this expected, or surprising? \n",
    "\n",
    "* Comment on any other aspects of your findings that are interesting to you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lr = np.reshape(feature_map_conv2,(np.shape(feature_map_conv2)[0],-1))\n",
    "y_lr = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your markdown here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Going for gold (15 points)\n",
    "\n",
    "The 2022 Winter Olympics just finished, and this problem will have you looking forward to summer. You will use Gaussian process regression to model the trends in gold medal performances of selected events in the summer Olympics. The objectives of this problem are for you to:\n",
    "\n",
    "* Gain experience with Gaussian processes, to better understand how they work\n",
    "* Explore how posterior inference depends on the properties of the prior mean and kernel\n",
    "* Use Bayesian inference to identify unusual events\n",
    "* Practice making your Python code modular and reusable\n",
    "\n",
    "For this problem, the only starter code we provide is to read in the data and extract \n",
    "one event. You may write any GP code that you choose to, but please do not use any \n",
    "package for Gaussian processes; your code should be \"np.complete\" (using only \n",
    "basic `numpy` methods). You are encouraged to start from the [GP demo code](https://ydata123.org/sp22/interml/calendar.html) used in class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we ran the GP demo code from class on the marathon data, it generated the following plot:\n",
    "<img src=\"https://github.com/YData123/sds365-sp22/raw/main/assignments/assn2/marathon.jpg\" width=\"600\">\n",
    "\n",
    "Note several properties of this plot:\n",
    "* It shows the Bayesian confidence of the regression, as a shaded area. This is a 95% confidence band because it has width given by $\\pm 2 \\sqrt{V}$, where $V$ is the estimated variance. The variance increases at the right side, for future years.\n",
    "\n",
    "* The gold medal time for the 1904 marathon is outside of this confidence band. In fact, \n",
    "the 1904 marathon was an [unusual event](https://www.smithsonianmag.com/history/the-1904-olympic-marathon-may-have-been-the-strangest-ever-14910747/), and this is apparent from the model. \n",
    "\n",
    "* The plot shows the posterior mean, and also shows one random sample from the posterior distribution.\n",
    "\n",
    "Your task in this problem is generate such a plot for six different Olympic events by writing a function\n",
    "\n",
    "`def gp_olympic_event(year, result, kernel, mean, noise, event_name):\n",
    "    ...`\n",
    "    \n",
    " where the input variables are the following:\n",
    " \n",
    "* `year`: a numpy array of years (integers)\n",
    "* `result`: a numpy array of numerical results, for the gold medal performances in that event\n",
    "* `kernel`: a kernel function \n",
    "* `mean`: a mean function \n",
    "* `noise`: a single float for the variance of the noise, $\\sigma^2$\n",
    "* `event_name`: a string used to label the y-axis, for example \"marathon min/mile (men's event)\"\n",
    " \n",
    "Your function should compute the Gaussian process regression, and then display the resulting plot, analogous to the plot above for the men's marathon event.\n",
    "\n",
    "You will then process **six** of the events, three men's events and three women's events, and call your function to generate the corresponding six plots.\n",
    "\n",
    "For each event, you should create a markdown cell that describes the resulting model. Comment on such things as:\n",
    "\n",
    "* How you chose the kernel, mean, and noise.\n",
    "* Why the plot does or doesn't look satisfactory to you\n",
    "* If there are any events such as the 1904 marathon that are notable.\n",
    "* What happens to the posterior mean (for example during WWII) if there are gaps in the data\n",
    "\n",
    "Use your best judgement to describe your findings; post questions to EdD if things are unclear. And have fun!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "\n",
    "In the remainder of this problem description, we recall how we processed the marathon data, as an example. The following cell reads in the data and displays the collection of events that are included in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Discus Throw Women', '20Km Race Walk Men', '20Km Race Walk Women', '800M Women', 'Long Jump Men', '400M Men', '4X400M Relay Men', 'Marathon Men', '400M Hurdles Women', '5000M Women', 'Shot Put Men', '110M Hurdles Men', '800M Men', '10000M Men', '400M Women', 'Javelin Throw Women', '10000M Women', '5000M Men', '1500M Women', 'Heptathlon Women', '100M Men', 'Shot Put Women', 'Pole Vault Men', '1500M Men', '400M Hurdles Men', 'High Jump Women', 'Triple Jump Women', 'Discus Throw Men', '4X100M Relay Men', 'Triple Jump Men', 'Long Jump Women', 'Hammer Throw Women', 'Decathlon Men', 'High Jump Men', 'Hammer Throw Men', '200M Women', '3000M Steeplechase Women', '3000M Steeplechase Men', '100M Women', 'Marathon Women', 'Pole Vault Women', '50Km Race Walk Men', 'Javelin Throw Men', '4X400M Relay Women', '100M Hurdles Women', '4X100M Relay Women', '200M Men'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dat = pd.read_csv('https://raw.githubusercontent.com/YData123/sds365-sp22/main/demos/gaussian_processes/olympic_results.csv')\n",
    "events = set(np.array(dat['Event']))\n",
    "print(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then process the time to compute the minutes per mile (without checking that the race was actually 26.2 miles!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Year</th>\n",
       "      <th>Medal</th>\n",
       "      <th>Name</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Result</th>\n",
       "      <th>Minutes per Mile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Athens</td>\n",
       "      <td>1896</td>\n",
       "      <td>G</td>\n",
       "      <td>Spyridon LOUIS</td>\n",
       "      <td>GRE</td>\n",
       "      <td>2:58:50</td>\n",
       "      <td>6.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paris</td>\n",
       "      <td>1900</td>\n",
       "      <td>G</td>\n",
       "      <td>Michel THÃATO</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2:59:45.0</td>\n",
       "      <td>6.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>St Louis</td>\n",
       "      <td>1904</td>\n",
       "      <td>G</td>\n",
       "      <td>Thomas HICKS</td>\n",
       "      <td>USA</td>\n",
       "      <td>3:28:53.0</td>\n",
       "      <td>7.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London</td>\n",
       "      <td>1908</td>\n",
       "      <td>G</td>\n",
       "      <td>John HAYES</td>\n",
       "      <td>USA</td>\n",
       "      <td>2:55:18.4</td>\n",
       "      <td>6.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stockholm</td>\n",
       "      <td>1912</td>\n",
       "      <td>G</td>\n",
       "      <td>Kennedy Kane MCARTHUR</td>\n",
       "      <td>RSA</td>\n",
       "      <td>2:36:54.8</td>\n",
       "      <td>5.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Antwerp</td>\n",
       "      <td>1920</td>\n",
       "      <td>G</td>\n",
       "      <td>Hannes KOLEHMAINEN</td>\n",
       "      <td>FIN</td>\n",
       "      <td>2:32:35.8</td>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Paris</td>\n",
       "      <td>1924</td>\n",
       "      <td>G</td>\n",
       "      <td>Albin STENROOS</td>\n",
       "      <td>FIN</td>\n",
       "      <td>2:41:22.6</td>\n",
       "      <td>6.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>1928</td>\n",
       "      <td>G</td>\n",
       "      <td>BoughÃ¨ra EL OUAFI</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2:32:57</td>\n",
       "      <td>5.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>1932</td>\n",
       "      <td>G</td>\n",
       "      <td>Juan Carlos ZABALA</td>\n",
       "      <td>ARG</td>\n",
       "      <td>2:31:36</td>\n",
       "      <td>5.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>1936</td>\n",
       "      <td>G</td>\n",
       "      <td>Kitei SON</td>\n",
       "      <td>JPN</td>\n",
       "      <td>2:29:19.2</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>London</td>\n",
       "      <td>1948</td>\n",
       "      <td>G</td>\n",
       "      <td>Delfo CABRERA</td>\n",
       "      <td>ARG</td>\n",
       "      <td>2:34:51.6</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Helsinki</td>\n",
       "      <td>1952</td>\n",
       "      <td>G</td>\n",
       "      <td>Emil ZÃTOPEK</td>\n",
       "      <td>TCH</td>\n",
       "      <td>2:23:03.2</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Melbourne / Stockholm</td>\n",
       "      <td>1956</td>\n",
       "      <td>G</td>\n",
       "      <td>Alain MIMOUN</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2:25:00</td>\n",
       "      <td>5.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rome</td>\n",
       "      <td>1960</td>\n",
       "      <td>G</td>\n",
       "      <td>Abebe BIKILA</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2:15:16.2</td>\n",
       "      <td>5.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>1964</td>\n",
       "      <td>G</td>\n",
       "      <td>Abebe BIKILA</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2:12:11.2</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>1968</td>\n",
       "      <td>G</td>\n",
       "      <td>Mamo WOLDE</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2:20:26.4</td>\n",
       "      <td>5.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Munich</td>\n",
       "      <td>1972</td>\n",
       "      <td>G</td>\n",
       "      <td>Frank Charles SHORTER</td>\n",
       "      <td>USA</td>\n",
       "      <td>2:12:19.8</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>1976</td>\n",
       "      <td>G</td>\n",
       "      <td>Waldemar CIERPINSKI</td>\n",
       "      <td>GDR</td>\n",
       "      <td>2:09:55.0</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Moscow</td>\n",
       "      <td>1980</td>\n",
       "      <td>G</td>\n",
       "      <td>Waldemar CIERPINSKI</td>\n",
       "      <td>GDR</td>\n",
       "      <td>2:11:03.0</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>1984</td>\n",
       "      <td>G</td>\n",
       "      <td>Carlos LOPES</td>\n",
       "      <td>POR</td>\n",
       "      <td>2:09:21</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Seoul</td>\n",
       "      <td>1988</td>\n",
       "      <td>G</td>\n",
       "      <td>Gelindo BORDIN</td>\n",
       "      <td>ITA</td>\n",
       "      <td>2:10:32</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Barcelona</td>\n",
       "      <td>1992</td>\n",
       "      <td>G</td>\n",
       "      <td>Young-Cho HWANG</td>\n",
       "      <td>KOR</td>\n",
       "      <td>2:13:23</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>1996</td>\n",
       "      <td>G</td>\n",
       "      <td>Josia THUGWANE</td>\n",
       "      <td>RSA</td>\n",
       "      <td>2:12:36</td>\n",
       "      <td>5.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>2000</td>\n",
       "      <td>G</td>\n",
       "      <td>Gezahegne ABERA</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2:10:11</td>\n",
       "      <td>4.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Athens</td>\n",
       "      <td>2004</td>\n",
       "      <td>G</td>\n",
       "      <td>Stefano BALDINI</td>\n",
       "      <td>ITA</td>\n",
       "      <td>2:10:55</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>2008</td>\n",
       "      <td>G</td>\n",
       "      <td>Samuel Kamau WANJIRU</td>\n",
       "      <td>KEN</td>\n",
       "      <td>2:06:32</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>London</td>\n",
       "      <td>2012</td>\n",
       "      <td>G</td>\n",
       "      <td>Stephen KIPROTICH</td>\n",
       "      <td>UGA</td>\n",
       "      <td>2:08:01</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Rio</td>\n",
       "      <td>2016</td>\n",
       "      <td>G</td>\n",
       "      <td>Eliud Kipchoge ROTICH</td>\n",
       "      <td>KEN</td>\n",
       "      <td>02:08:44</td>\n",
       "      <td>4.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Location  Year Medal                   Name Nationality  \\\n",
       "0                  Athens  1896     G         Spyridon LOUIS         GRE   \n",
       "1                   Paris  1900     G         Michel THÃATO         FRA   \n",
       "2                St Louis  1904     G           Thomas HICKS         USA   \n",
       "3                  London  1908     G             John HAYES         USA   \n",
       "4               Stockholm  1912     G  Kennedy Kane MCARTHUR         RSA   \n",
       "5                 Antwerp  1920     G     Hannes KOLEHMAINEN         FIN   \n",
       "6                   Paris  1924     G         Albin STENROOS         FIN   \n",
       "7               Amsterdam  1928     G     BoughÃ¨ra EL OUAFI         FRA   \n",
       "8             Los Angeles  1932     G     Juan Carlos ZABALA         ARG   \n",
       "9                  Berlin  1936     G              Kitei SON         JPN   \n",
       "10                 London  1948     G          Delfo CABRERA         ARG   \n",
       "11               Helsinki  1952     G          Emil ZÃTOPEK         TCH   \n",
       "12  Melbourne / Stockholm  1956     G           Alain MIMOUN         FRA   \n",
       "13                   Rome  1960     G           Abebe BIKILA         ETH   \n",
       "14                  Tokyo  1964     G           Abebe BIKILA         ETH   \n",
       "15                 Mexico  1968     G             Mamo WOLDE         ETH   \n",
       "16                 Munich  1972     G  Frank Charles SHORTER         USA   \n",
       "17               Montreal  1976     G    Waldemar CIERPINSKI         GDR   \n",
       "18                 Moscow  1980     G    Waldemar CIERPINSKI         GDR   \n",
       "19            Los Angeles  1984     G           Carlos LOPES         POR   \n",
       "20                  Seoul  1988     G         Gelindo BORDIN         ITA   \n",
       "21              Barcelona  1992     G        Young-Cho HWANG         KOR   \n",
       "22                Atlanta  1996     G         Josia THUGWANE         RSA   \n",
       "23                 Sydney  2000     G        Gezahegne ABERA         ETH   \n",
       "24                 Athens  2004     G        Stefano BALDINI         ITA   \n",
       "25                Beijing  2008     G   Samuel Kamau WANJIRU         KEN   \n",
       "26                 London  2012     G      Stephen KIPROTICH         UGA   \n",
       "27                    Rio  2016     G  Eliud Kipchoge ROTICH         KEN   \n",
       "\n",
       "       Result  Minutes per Mile  \n",
       "0     2:58:50              6.83  \n",
       "1   2:59:45.0              6.86  \n",
       "2   3:28:53.0              7.97  \n",
       "3   2:55:18.4              6.69  \n",
       "4   2:36:54.8              5.99  \n",
       "5   2:32:35.8              5.82  \n",
       "6   2:41:22.6              6.16  \n",
       "7     2:32:57              5.84  \n",
       "8     2:31:36              5.79  \n",
       "9   2:29:19.2              5.70  \n",
       "10  2:34:51.6              5.91  \n",
       "11  2:23:03.2              5.46  \n",
       "12    2:25:00              5.53  \n",
       "13  2:15:16.2              5.16  \n",
       "14  2:12:11.2              5.05  \n",
       "15  2:20:26.4              5.36  \n",
       "16  2:12:19.8              5.05  \n",
       "17  2:09:55.0              4.96  \n",
       "18  2:11:03.0              5.00  \n",
       "19    2:09:21              4.94  \n",
       "20    2:10:32              4.98  \n",
       "21    2:13:23              5.09  \n",
       "22    2:12:36              5.06  \n",
       "23    2:10:11              4.97  \n",
       "24    2:10:55              5.00  \n",
       "25    2:06:32              4.83  \n",
       "26    2:08:01              4.89  \n",
       "27   02:08:44              4.91  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marathon = dat[dat['Event'] == 'Marathon Men']\n",
    "marathon = marathon[marathon['Medal']=='G']\n",
    "marathon = marathon.sort_values('Year')\n",
    "time = np.array(marathon['Result'])\n",
    "mpm = []\n",
    "for tm in time:\n",
    "    t = np.array(tm.split(':'), dtype=float)\n",
    "    minutes_per_mile = (t[0]*60*60 + t[1]*60 + t[2])/(60*26.2)\n",
    "    mpm.append(minutes_per_mile)\n",
    "    \n",
    "marathon['Minutes per Mile'] = np.round(mpm,2)\n",
    "marathon = marathon.drop(columns=['Gender', 'Event'], axis=1)\n",
    "marathon.reset_index(drop=True, inplace=True)\n",
    "year = np.array(marathon['Year'])\n",
    "result = np.array(marathon['Minutes per Mile'])\n",
    "marathon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter your code and markdown following this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: It's the process, not the product (15 points)\n",
    "\n",
    "In this problem, you will explore the properties of the Dirichlet process, \n",
    "and get some practice drawing samples from a DP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Be consistent\n",
    "\n",
    "Let $F\\sim \\mbox{DP}(\\alpha,F_0)$ be drawn from a Dirichlet process with parameters $\\alpha$ and $F_0$. Show that $\\mathbb{E}(F)=F_0$.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2:  Concentrate\n",
    "\n",
    "If $F\\sim \\mbox{DP}(\\alpha,F_0)$, show that the prior gets more concentrated around $F_0$ as $\\alpha \\to\n",
    "\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3:  Repeat after me\n",
    "\n",
    "Let $F\\sim \\mbox{DP}(\\alpha,F_0)$ be drawn from a Dirichlet process with parameters $\\alpha$ and $F_0$, and let $X_1, X_2, \\ldots, X_n \\;|\\; F \\sim F$ be drawn from $F$.\n",
    "What is the posterior mean of $F(x)$ given $X_1, \\ldots, X_n$?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4: Seeing is believing\n",
    "\n",
    "Write Python code to illustrate property 3.1 above: $\\mathbb{E} F(x) = F_0(x)$.\n",
    "Take the [DP demo code](https://ydata123.org/sp22/interml/calendar.html) used in class as a starting point. You should draw many samples from the prior, average them, and then compare\n",
    "to $F_0$. You can let $F_0$ be Gaussian or another distribution. Try several different values of $\\alpha$.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
